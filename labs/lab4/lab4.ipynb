{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSCI 572 Lab 4\n",
    "<!-- rubric={mechanics:3} -->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from scipy.signal import convolve2d\n",
    "\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.transform import resize\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.size'] = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.optimizers import Adam, SGD\n",
    "\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from keras.applications.inception_v3 import InceptionV3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "rubric={mechanics:5}\n",
    "\n",
    "Follow the [general lab instructions](https://ubc-mds.github.io/resources_pages/general_lab_instructions/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: convolutions\n",
    "\n",
    "For each of the filters given below, convolve the given image (or a different image of your choice) with the given filter and discuss why the results look the way they do. \n",
    "\n",
    "You can perform 2D convolutions using [`scipy.signal.convolve2d`](https://docs.scipy.org/doc/scipy-0.18.1/reference/generated/scipy.signal.convolve2d.html).\n",
    "\n",
    "The suggested image size is around 100x100 pixels; if the image is too big, it will be hard to see the changes by eye using the very small filters given below. If you want to make an image smaller, try [scipy.misc.imresize](https://docs.scipy.org/doc/scipy-0.18.1/reference/generated/scipy.misc.imresize.html). This will be a lot faster than seam carving :)\n",
    "\n",
    "Note: depending on your versions of various packages, you might get warnings when you run the code. It's OK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(filename):\n",
    "    img = plt.imread(filename) # read in the image\n",
    "    img = resize(img, (100,100), mode='reflect') # resize it if you want\n",
    "    return rgb2gray(img) # make it grayscale\n",
    "\n",
    "def show_conv(img, filt):\n",
    "\n",
    "    plt.figure(figsize=(8,16))\n",
    "    plt.subplot(1,2,1)\n",
    "    \n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "    plt.title(\"original\")\n",
    "    I_filt = convolve2d(img,filt, boundary='symm', mode='same')\n",
    "\n",
    "    I_filt = np.maximum(0, I_filt) # set negative values to 0, for visualization purposes\n",
    "    I_filt = np.minimum(1, I_filt) # set values greater than 1 to 1, for visualization purposes\n",
    "    plt.subplot(1,2,2)\n",
    "    if np.sum(filt) == 0: # a trick to make the images easier to see, not part of the \"math\"\n",
    "        plt.imshow(I_filt/np.max(I_filt), cmap='gray')\n",
    "    else:\n",
    "        plt.imshow(I_filt, cmap='gray')\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "    plt.title(\"filtered\")\n",
    "\n",
    "    return I_filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = preprocess_image(\"milad_cropped.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example, you don't need to do this one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft = 0.1*np.ones(10)[None]\n",
    "print(ft.shape)\n",
    "print(ft)\n",
    "\n",
    "res = show_conv(img, ft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Sample answer: **\n",
    "The filter is a horizontal bar all containing $0.1$. Therefore I would expect a blurring in the horizontal direction, meaning the _vertical_ edges get blurred (because these are the ones that change rapidly in the horizontal direction). This seems to be happening in the result. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1(a)\n",
    "rubric={reasoning:1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft = 0.1*np.ones(10)[:,None]\n",
    "print(ft.shape)\n",
    "print(ft)\n",
    "\n",
    "res = show_conv(img, ft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1(b)\n",
    "rubric={reasoning:1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft = np.zeros((5,5))\n",
    "ft[2,2] = 1\n",
    "print(ft.shape)\n",
    "print(ft)\n",
    "res = show_conv(img, ft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1(c)\n",
    "rubric={reasoning:1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft = 0.01*np.ones((10,10))\n",
    "print(ft.shape)\n",
    "res = show_conv(img, ft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1(d)\n",
    "rubric={reasoning:1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft = -np.ones((3,3))/8\n",
    "ft[1,1] = 1\n",
    "print(ft.shape)\n",
    "print(ft)\n",
    "res6 = show_conv(img, ft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (optional) 1(e)\n",
    "rubric={reasoning:1}\n",
    "\n",
    "Earlier in this course we talked about gradients and numerical differentiation. Think about part (d) above: does this have anything to do with the topics from earlier on? Can you relate these edge detection operations to \"derivatives\" or \"gradients\"?\n",
    "\n",
    "Also, by the way, back in the seam carving lab of DSCI 512 we gave you a function that calculated the \"energy\" of an image, and we then looked for low energy seams. Here's the code we gave you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage.filters import convolve\n",
    "\n",
    "def energy(image): \n",
    "    dy = np.array([-1, 0, 1])[:,None,None]\n",
    "    dx = np.array([-1, 0, 1])[None,:,None]\n",
    "    energy_img = convolve(image, dx)**2 + convolve(image, dy)**2\n",
    "    return np.sum(energy_img, axis=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(There's no particular reason I switched from [`scipy.ndimage.filters.convolve`](https://docs.scipy.org/doc/scipy-0.16.1/reference/generated/scipy.ndimage.filters.convolve.html) to [`scipy.signal.convolve2d`](https://docs.scipy.org/doc/scipy-0.18.1/reference/generated/scipy.signal.convolve2d.html); they perform the same function for our purposes.) I thought you might enjoy looking back at this formerly mysterious code with your newfound knowledge. And it's also a bit of a hint: the seam carving energy function looked for \"edges\" or \"changes\" or ... derivatives! The above actually calculates the magnitude squared of the \"gradient\" at every point. The whole thing should make sense now as well -- when seam carving we wanted to remove pixels for which there wasn't much going on in the immediate vicinity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2. Convolutional networks for MNIST\n",
    "\n",
    "Sorry to continue with MNIST so long. It's just _THE_ classic data set for this stuff.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is some code that trains a convnet on MNIST. The code is adapted from the book [Deep Learning with Python](https://machinelearningmastery.com/deep-learning-with-python/) with permission from the author. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# reshape to be [samples][channels][width][height]\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32')\n",
    "\n",
    "# normalize inputs from 0-255 to 0-1\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "\n",
    "# one hot encode outputs\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a subset of the data for speed\n",
    "subset_size = 10000\n",
    "X_train = X_train[:subset_size]\n",
    "y_train = y_train[:subset_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a simple CNN model\n",
    "mnist_model = Sequential()\n",
    "mnist_model.add(Conv2D(32, (5, 5), input_shape=(28, 28, 1), activation='relu'))\n",
    "mnist_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "mnist_model.add(Dropout(0.2))\n",
    "mnist_model.add(Flatten())\n",
    "mnist_model.add(Dense(128, activation='relu'))\n",
    "mnist_model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Compile model\n",
    "mnist_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "mnist_model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=256)\n",
    "# Final evaluation of the model\n",
    "scores = mnist_model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"CNN Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2(a)\n",
    "rubic={reasoning:3}\n",
    "\n",
    "Run the code above. How does it compare to your fully-connected (\"Dense\") neural net from lab 3? Discuss in 2-3 sentences. (Keep in mind that here we're only using a subset of the training data for speed.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2(b)\n",
    "rubric={reasoning:6}\n",
    "\n",
    "You will now deploy Keras/TensorFlow on the cloud using [Google Colab](https://colab.research.google.com/). This will allow you to train on a GPU and assess the benefits of training neural networks on GPUs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow these steps:\n",
    "\n",
    "1. Save this Jupyter notebook so that it contains your latest work. Also push it to GitHub to be safe.\n",
    "2. Go to https://colab.research.google.com/.\n",
    "3. Make an account if you don't have one.\n",
    "4. Select \"UPLOAD\" and upload this notebook itself, lab4.ipynb, which you just saved.\n",
    "5. Runtime --> change runtime type --> Select GPU.\n",
    "\n",
    "**SUGGESTION:** once you're done all your work on Colab (which means this exercise and the next one), you can download the notebook from Colab and overwrite your local version. That way any work you did on Colab won't be lost. (They allow working directly off a notebook on GitHub, but that feature won't work for us since we're using github.ubc.ca.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, run the same MNIST experiment as above but on Google Colab with the GPU. \n",
    "\n",
    "1. How much faster is it (as a ratio) to run the exact same code on the GPU vs. your laptop? \n",
    "2. Notice the code above takes a subset of 10,000 training examples for speed. With the speed of the GPU, you should now use the full 60,000 training examples on AWS. Report your performance after 10 epochs when training on the full data set. How does it compare to the validation error you were able to get on your local machine (which presumably required using the smaller training set to run in reasonable time)? \n",
    "3. Again, compare to the fully connected network from lab 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (optional) 2(c)  TensorFlow vs. Theano\n",
    "rubric={reasoning:1}\n",
    "\n",
    "Compare the speed/accuracy of TensorFlow vs. Theano with your experiments. To switch backends, \n",
    "\n",
    "```python\n",
    "import os\n",
    "os.environ['KERAS_BACKEND'] = 'theano'\n",
    "```\n",
    "\n",
    "should work. When you `import keras` in Python it tells you which backend it is using, so you will be able to verify that you successfully switched backends. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (optional, silly) 2(d): how hot can you make your GPU?\n",
    "\n",
    "Note: this is not worth any bonus points, it's just for fun.\n",
    "\n",
    "If you run `!nvidia-smi` in Colab, you'll see some diagnostics about your GPU. What is the GPU temperature \"at rest\"? How hot can you make the GPU by asking it to crunch a lot of numbers? (I wonder if your GPU is being shared with other people - probably! So, perhaps it's already hot to begin with?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kXIVN3thVXPh"
   },
   "source": [
    "## Exercise 3: Transfer learning\n",
    "\n",
    "In this exercise we will work on the concept of _transfer learning_, in which we'll use a model trained on one task as a starting point for learning to perform another task. \n",
    "\n",
    "A natural question is, why is transfer learning helpful to us? Why can't we just train a model with the second task's objectives from the beginning? \n",
    "A key motivation is the difficult in obtaining labeled data: ususally we need a whole lot of data in order to solve complex problems, and it can be hard to collect the data. (Another motivation is the time and effort -- both computational time and human time -- needed to train the original model. Someone did the work already, so we don't have to.)\n",
    "\n",
    "In this exercise we'll explore another application of transfer learning: fine-grained image classification. Here, the goal is to recognize different subclasses within a higher-level class. In our case, the higher level question could be, \"Is this a dog?\" and the fine-grained question is, \"What breed of dog is this?\"\n",
    "\n",
    "We will use the [Kaggle dog breed identification](https://www.kaggle.com/c/dog-breed-identification/data) dataset. \n",
    "In the dataset, each dog image is labeled according to one of 120 breeds. We'll base our models on a model that was already trained for a more high-level image classification task, namely the famous [ImageNet dataset](http://www.image-net.org/). You can see some sample ImageNet images [here](http://image-net.org/explore?wnid=n04516672).\n",
    "\n",
    "We'll consider three approaches to the dog breed classification problem:\n",
    "\n",
    "1. No transfer learning, just end-to-end training of a CNN directly for the dog breed classification task.\n",
    "2. Use a pre-trained model as a feature extractor; then, add new layers in order to train it with the dog-breed dataset.\n",
    "3. Some fine tuning of the weights of the pre-trained model (instead of freezing them all and only adding new layers, is in approach 2).\n",
    "\n",
    "Attribution: In designing this exercise, we took some inspiration from [here](https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html). But I think our version is more interesting because the classes in our new task are not part of the original task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X080337PVXQg"
   },
   "source": [
    "### Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Go to https://www.kaggle.com/c/dog-breed-identification/rules, make sure you're signed in to Kaggle, and accept the competition rules.\n",
    "- Go to kaggle.com, click on your picture in the upper-right, go to Acconut, scroll down, hit \"Create New API token\". This should download a file.\n",
    "\n",
    "\n",
    "### What you should do\n",
    "\n",
    "As with the previous exercise, you should do this on the GPU on Colab. Your task for now is to read along and, **whenever there are code cells below, you should run them as you go along.** There will be some questions interspersed in the document, **which you should answer**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -q kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.upload()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running the cell above, a \"Choose File\" button should appear. Press this and select the file that you just downloaded, probably called `kaggle.json`, which contains your Kaggle API token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir ~/.kaggle\n",
    "! cp kaggle.json ~/.kaggle/\n",
    "! chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! kaggle competitions download -c dog-breed-identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! unzip -q train.zip\n",
    "! unzip -q labels.csv.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we take only the first 2000 samples from the original dataset. We want to simulate having only a small labeled dataset available to us, and see the effect of transfer learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "F3uwOqqNVXQl",
    "outputId": "5ffb577b-1359-431b-e273-d0f515418b49"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('labels.csv')\n",
    "data = data[:2000]\n",
    "data['image_path'] = data.apply( lambda row: (os.path.join(\"train\", row[\"id\"] + \".jpg\") ), axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above: you can see some of the breeds that we're predicting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "Hw0kE6BgVXQr",
    "outputId": "5fe446d1-8001-4ad2-d116-67b6db50ad2e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "target_labels = data['breed']\n",
    "total_classes = len(set(target_labels))\n",
    "print(\"number of dog breeds:\", total_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xTCKP_rhVXQ5"
   },
   "outputs": [],
   "source": [
    "# read images from the image directory. \n",
    "images = np.array([img_to_array(\n",
    "                    load_img(img, target_size=(256,256))\n",
    "                    ) for img in data['image_path'].values.tolist()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "EtOYBdEiVXQ9",
    "outputId": "e6ee4d60-5b61-48c2-dcf0-66ee92404a5b"
   },
   "outputs": [],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above: we have 2000 images, each of size $256 \\times 256$ and with 3 colour channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images.astype('float32')/255.0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above: it's very important to scale the images!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(images[0]);\n",
    "plt.grid(True);\n",
    "plt.xticks([]);\n",
    "plt.yticks([]);\n",
    "plt.title(\"Breed = \" + target_labels[0]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above: this is a sample image from the dog breed data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r8s5GlKHVXRF"
   },
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(images, target_labels, \n",
    "                                                    stratify=np.array(target_labels), \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "4AxPhnaUVXRI",
    "outputId": "097a2fe8-eae2-4223-80aa-a4aa68fc802e"
   },
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3(a)\n",
    "rubric={reasoning:1}\n",
    "\n",
    "How many training examples do we have per breed of dog, roughly? In the context of other classification tasks we've done in MDS, do you consider this to be a lot or a little?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_answer here_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we do the one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "cy0xw3hVVXRM",
    "outputId": "7ee8a52b-d937-44c1-b9ba-c1db7bdaaa93"
   },
   "outputs": [],
   "source": [
    "Y_train = pd.get_dummies(y_train.reset_index(drop=True)).as_matrix()\n",
    "Y_valid = pd.get_dummies(y_valid.reset_index(drop=True)).as_matrix()\n",
    "\n",
    "print(Y_train.shape)\n",
    "print(Y_valid.shape)\n",
    "\n",
    "# Note to future self (Mike 2020): it would be better to use keras.utils.to_categorical, \n",
    "# just in case one of the classes is absent in one of the two sets.\n",
    "# But this works for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0oMSfTq8VXRd"
   },
   "source": [
    "### Approach 1\n",
    "\n",
    "Now, we try Approach 1, which is training an end-to-end CNN on the dog breed classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nyo9AZskVXRe"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(256, 256, 3)))\n",
    "model.add(Activation('relu')) # this is just different syntax for specifying the activation function\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 659
    },
    "colab_type": "code",
    "id": "UEprOsdpVXRh",
    "outputId": "df370fa9-8182-47f2-b4e0-7c2428035281"
   },
   "outputs": [],
   "source": [
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(total_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "both",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "colab_type": "code",
    "id": "4MWU2eWTVXRn",
    "outputId": "ab226d03-b0c0-465e-e0b6-76940acb443f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(X_train, Y_train, epochs=10, validation_data=(X_valid, Y_valid))\n",
    "\n",
    "# FYI: it's often a good idea to save your weights after training or during training.\n",
    "# But you don't have to here.\n",
    "# model.save_weights('my_conv_net.h5')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3(b)\n",
    "rubric={reasoning:1}\n",
    "\n",
    "What do you think of the results? Are you impressed? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8BSLsVLXVXRr"
   },
   "source": [
    "### Approach 2\n",
    "\n",
    "Here we load a pre-trained model and add some layers on top. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "JAebsZBqVXRt",
    "outputId": "60e2b071-3da3-4107-b6b8-fc0681805141"
   },
   "outputs": [],
   "source": [
    "# Get the InceptionV3 model trained on the ImageNet data set\n",
    "base_inception = InceptionV3(weights='imagenet', include_top=False, input_shape=(256, 256, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the `include_top=False`. This throws away the last layer. It wasn't useful to us anyway. ImageNet has 1000 classes, but we're not interested in those classes. Another way to think of it is that the original model is a crazy feature extractor plus logistic regression for the 1000 ImageNet classes. We are using the feature extractor and discarding the logistic regression part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IJnDwXjjVXR4"
   },
   "outputs": [],
   "source": [
    "top_block = base_inception.output\n",
    "top_block = GlobalAveragePooling2D()(top_block) # pool over height/width to reduce number of parameters\n",
    "top_block = Dense(256, activation='relu')(top_block) # add a Dense layer\n",
    "predictions = Dense(total_classes, activation='softmax')(top_block) # add another Dense layer\n",
    "\n",
    "model_transfer = Model(inputs=base_inception.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above: the syntax is not what you're used to - that's OK, don't worry about it.  If you want to know more, see [this documentation](https://keras.io/models/model/). However, at a high level we're grabbing the base model, doing some pooling, and then adding two new dense layers at the top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 11631
    },
    "colab_type": "code",
    "id": "txHFPz5eVXR7",
    "outputId": "54befe91-c1b5-44ad-f59f-7396dd140dfb"
   },
   "outputs": [],
   "source": [
    "for layer in base_inception.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above: this is a key step. We \"freeze\" the layers of the base model, so that only our two new Dense layers at the top are trainable. That means we only update the weights in the new top layers - all the other weights (the ones from the base model) are fixed (\"frozen\") during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "colab_type": "code",
    "id": "hoqUIzlRVXR-",
    "outputId": "51ba1c31-57d0-4b4a-a74c-1e833b8dd180",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_transfer.compile(Adam(lr=.001), loss='categorical_crossentropy', metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_transfer.summary() # run me if you dare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above: that's a lot of layers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model_transfer.fit(X_train, Y_train, validation_data=(X_valid, Y_valid), epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oQBtEHkh517q"
   },
   "source": [
    "#### 3(c)\n",
    "rubric={reasoning:1}\n",
    "\n",
    "How does this result compare to the \"from scratch\" CNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PLeqHLO3VXSB"
   },
   "source": [
    "### Approach 3\n",
    "\n",
    "Below, we un-freeze the last \"15\" layers, which is really only the last one or two layers, since the list of Keras layer objects doesn't really correspond to our idea of a layer (see `model.summary()`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BlBgaXPlVXSL"
   },
   "outputs": [],
   "source": [
    "for i, layer in enumerate(reversed(model_transfer.layers)):\n",
    "    layer.trainable = True\n",
    "#     print(layer)\n",
    "    if i > 15:\n",
    "        break\n",
    "\n",
    "# compile the model with a SGD/momentum optimizer and a very slow learning rate.\n",
    "model_transfer.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(lr=1e-4, momentum=0.9),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 381
    },
    "colab_type": "code",
    "id": "0pkUjUCzVXSO",
    "outputId": "3059d966-1353-4b1f-cd44-279f30288785"
   },
   "outputs": [],
   "source": [
    "# fine-tune the unfrozen layers\n",
    "history = model_transfer.fit(X_train, Y_train, validation_data=(X_valid, Y_valid), epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (optional) 3(d)\n",
    "rubric={reasoning:1}\n",
    "\n",
    "Un-freezing some of the layers seems to have a small effect here. Was it actually useful at all, or could we have achieved the same results by just training our top layers for more epochs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3(e)\n",
    "rubric={reasoning:1}\n",
    "\n",
    "In Lab 3 we noticed that unlike scikit-learn's `fit`, Keras's `fit` doesn't re-initialize the weights, but rather continues on from where you were. In the above code, we benefitted from this. Briefly describe how/why this behaviour was useful to us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3(f)\n",
    "rubric={reasoning:3}\n",
    "\n",
    "Brainstorm 3 other applications of this type of transfer learning, where you use a pre-trained network plus some modifications. In each case, what is the original task and what is the new task? (It's OK if you don't actually have access to a pre-trained network to do the original task; we're just brainstorming here.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(You are now done with Colab. If you were editing the file there, you should download it to your local machine before closing Colab!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: Pondering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4(a) \n",
    "rubric={reasoning:2}\n",
    "\n",
    "When we previously worked on the handwritten digits dataset, we did something quite silly: we \"flattened\" images into vectors; for example $28\\times 28$ MNIST images became vectors of length $28\\times 28 = 784$. This is arguably insane! One reason it's insane is that we were completely discarding the \"spatial information\" contained in the image and just pretended we had 784 different features, whereas convnets preserve the 2D structure and take 2D convolutions. But there is another, related reason it's a bad idea to just flatten the images... what would go wrong if we tried to use fully connected nets on larger images, like $1000 \\times 1000$ pixels?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4(b)\n",
    "rubric={raw:3}\n",
    "\n",
    "For each of the following, would increasing this quantity typically increase, decrease, or have no effect on the number of parameters of the model? No need to explain. \n",
    "\n",
    "1. Dropout probability, e.g. `0.2`\n",
    "2. Filter size, e.g. `(5,5)`\n",
    "3. Number of filters, e.g. `32`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4(c)\n",
    "rubric={raw:3}\n",
    "\n",
    "For each of the following, would increasing this quantity typically increase, decrease, or have no effect on the training error? No need to explain. \n",
    "\n",
    "1. Dropout probability, e.g. `0.2`\n",
    "2. Filter size, e.g. `(5,5)`\n",
    "3. Number of filter, e.g. `32`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4(d)\n",
    "rubric={reasoning:3}\n",
    "\n",
    "What are the pros/cons of neural nets, vs. approaches previously learned (for both regression and classification)? Choose one method from a previous course (561, 571, 573) and compare it with what you've done in deep learning. Write a paragraph summarizing the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------\n",
    "\n",
    "All the rest are optional; if you want to be done, you're done!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (optional) 4(e) \n",
    "rubric={reasoning:1}\n",
    "\n",
    "The code below shows that the MNIST model from Exercise 2 has 592,074 parameters. Explain where this number comes from by going layer by layer and accounting for all the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in model.get_weights():\n",
    "    print(w.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (optional) 4(f)\n",
    "rubric={reasoning:1}\n",
    "\n",
    "Consider this CNN architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (5, 5), input_shape=(28, 28, 1), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(32, (5, 5), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we remove (comment out) pooling from the _first_ convolutional layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (5, 5), input_shape=(28, 28, 1), activation='relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(32, (5, 5), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why does this change increase the number of parameters in the 3rd (Dense) layer, but not in the 2nd (Conv2D) layer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (optional) 4(g) \n",
    "rubric={reasoning:1}\n",
    "\n",
    "In the code above, the data is transformed to `float32` type. In lecture we discussed floating point representations. The main advantage of using 32-bit floating point numbers (versus 64-bit) is computational speed, but there's a disadvantage in terms of accuracy. Think about dropout and what it does/accomplishes. Did thinking about dropout alleviate your concerns about the potential pitfalls of using a smaller floating point represntation? Briefly discuss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (optional) 4(h)\n",
    "rubric={reasoning:1}\n",
    "\n",
    "If you had access to 1000 GPUs, do you think you could get 1000x performance? If not, why? What are the limitations/bottlenecks?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
