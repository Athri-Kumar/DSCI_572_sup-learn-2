{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Athri-Kumar/DSCI_572_sup-learn-2/blob/master/EE599_ML_Systems_HW6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxH3R-8OZOpk"
      },
      "source": [
        "# HW6 EE599 Systems for Machine Learning, Fall 2023\n",
        "University of Southern California\n",
        "\n",
        "Instructors: Arash Saifhashemi, Murali Annavaram\n",
        "\n",
        "In this homework assignment, we're going to implement DP-SGD for neural networks! Recall from the class that classical ML models possessed convenient properties such as Convexity and L-Lipschitzness which make the DP analysis easy. However, modern neural networks, like the one we'll be working with, does not have these properties. Thus, we need to modify the training algorithm, gradient descent, so that the trained model is DP.\n",
        "\n",
        "## Prerequisites:\n",
        "\n",
        "Set the runtime type to GPU. (Runtime -> Change Runtime Type)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQQk25oQCo8f"
      },
      "source": [
        "## Mount Google Drive\n",
        "\n",
        "Create a folder named `HW6` under `ML_Systems` in your Google drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezmjLOr6Co8f",
        "outputId": "baf602e0-a1d1-4939-df92-423dd4f0217e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "import sys, os\n",
        "\n",
        "data_dir = \"/content/drive/MyDrive/ML_Systems/HW6/data\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1ODkkuwZTSD"
      },
      "source": [
        "## Initial Setup\n",
        "\n",
        "This section imports all required packages from PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FnT0mf2l0hUC",
        "outputId": "663d99b4-91b6-4efc-f398-4dbcd92f8598"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7c54fe672810>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "\n",
        "torch.manual_seed(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3B5DlxLjCo8g"
      },
      "source": [
        "**Reminder:** set the runtime type to \"GPU\", or your code will run much more slowly on a CPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "22wBDD60Co8h",
        "outputId": "ff57d63b-f35e-48cb-9500-381e965ff80c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"CUDA\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQA2aMuNbv48"
      },
      "source": [
        "Define model architecture and prepare dataset, which are the same as the previous homework."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Km-kc-wa0n5d"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        # Define the layers of the neural network architecture\n",
        "\n",
        "        # First convolutional layer: 3 input channels, 6 output channels, kernel size 5x5\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5, bias=False)\n",
        "\n",
        "        # Max pooling layer with kernel size 2x2 and stride 2\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        # Second convolutional layer: 6 input channels, 16 output channels, kernel size 5x5\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5, bias=False)\n",
        "\n",
        "        # Fully connected (dense) layers\n",
        "\n",
        "        # First fully connected layer: 16*5*5 input features, 120 output features\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120, bias=False)\n",
        "\n",
        "        # Second fully connected layer: 120 input features, 84 output features\n",
        "        self.fc2 = nn.Linear(120, 84, bias=False)\n",
        "\n",
        "        # Third fully connected layer: 84 input features, 10 output features (for classification)\n",
        "        self.fc3 = nn.Linear(84, 10, bias=False)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        # Forward pass through the neural network\n",
        "\n",
        "        # Apply first convolutional layer, followed by ReLU activation and max pooling\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "\n",
        "        # Apply second convolutional layer, followed by ReLU activation and max pooling\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "\n",
        "        # The output from the convolutional and pooling layers is in the form of a\n",
        "        # 3D tensor (height, width, depth or channels).\n",
        "        # To feed this tensor into a fully connected layer,\n",
        "        # it needs to be flattened into a 1D tensor.\n",
        "        # Reshape tensor for fully connected layers\n",
        "        # A2D tensor with a shape of [batch_size, 16 * 5 * 5].\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "\n",
        "        # Apply first fully connected layer, followed by ReLU activation\n",
        "        x = F.relu(self.fc1(x))\n",
        "\n",
        "        # Apply second fully connected layer, followed by ReLU activation\n",
        "        x = F.relu(self.fc2(x))\n",
        "\n",
        "        # Apply third fully connected layer (output layer)\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "heygH3k7ZI0L"
      },
      "outputs": [],
      "source": [
        "# A function to evaluate the performance of a given neural network model\n",
        "# using a test dataset.\n",
        "# It calculates the accuracy of the model's predictions on the test data.\n",
        "def calculate_accuracy(\n",
        "    model: nn.Module, dataloader: DataLoader, max_samples=None\n",
        ") -> float:\n",
        "    correct_predictions = 0  # Initialize the count of correctly predicted samples\n",
        "    total_samples = 0  # Initialize the count of total samples\n",
        "    inference_count = 0  # Initialize the count of inferences made\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient calculation for inference\n",
        "        for batch_data in dataloader:\n",
        "            images, labels = batch_data  # Separate images and labels from the batch\n",
        "\n",
        "            images = images.to(device)  # Move images to the specified device\n",
        "            labels = labels.to(device)  # Move labels to the specified device\n",
        "\n",
        "            outputs = model(images)  # Forward pass to get model predictions\n",
        "            _, predicted = torch.max(outputs.data, 1)  # Get predicted class indices\n",
        "\n",
        "            total_samples += labels.size(0)  # Increment the total count of samples\n",
        "            correct_predictions += (\n",
        "                (predicted == labels).sum().item()\n",
        "            )  # Count correct predictions\n",
        "\n",
        "            if (\n",
        "                max_samples\n",
        "            ):  # Check if a maximum number of samples for testing is specified\n",
        "                inference_count += images.shape[\n",
        "                    0\n",
        "                ]  # Increment the count of inferences made\n",
        "                if (\n",
        "                    inference_count > max_samples\n",
        "                ):  # Stop testing if maximum samples reached\n",
        "                    break\n",
        "\n",
        "    accuracy = (\n",
        "        100 * correct_predictions / total_samples\n",
        "    )  # Calculate the accuracy as a percentage\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tIgKCdRcmB8"
      },
      "source": [
        "## DP Hyperparamters\n",
        "Here is where we will defined the different hyperparameters needed for DP-SGD.\n",
        "* $N = 2048$: Number of datapoints we are using. Since DP-SGD takes extremely long to run, we will only use a subset of the total CIFAR-10 dataset\n",
        "* $C = 1.0$: This is the clipping threshold. If $||∇L(x, y)||_{2} > C$ then we divide by $||∇L(x, y)||_{2}$.\n",
        "* $E = 20$: Number of epochs to run DP-SGD\n",
        "* $q = batch\\_size / N$: This is the sample probability. Since we are grouping the dataset into batches, each batch can be thought of as being sampled.\n",
        "* $T = \\frac{E}{q}$: number of iterations. This is more of an internal value used to calculate the DP parameter values, because DP-SGD is measured in terms of iterations, not epochs. But we can convert from Epochs to iterations.\n",
        "* $\\sigma$: The noise multiplier used to add noise to the gradients. As $\\sigma$ gets larger, the privacy guarantee improves but the variance of the noise increases, which can reduce the accuracy or utility. The choice of $\\sigma$ is often related to the desired $\\varepsilon$ value; achieving a lower\n",
        "$\\varepsilon$ (stronger privacy) typically requires a higher\n",
        "$\\sigma$.\n",
        "\n",
        "* $\\delta = 10^{-5}$: This is the probability of failure. We will set this to a default value.\n",
        "* $\\varepsilon = \\frac{q * \\sqrt{T * \\log(1 / \\delta)}}{\\sigma}$: the privacy loss, which is a function of the other hyperparameters. It quantifies the strength of the privacy guarantee. In DP, $\\varepsilon$ is used to define the level of indistinguishability that the algorithm ensures between outputs generated from datasets that differ by a single element. A smaller value means  a stronger privacy guarantee, meaning the outputs of the algorithm are more similar (indistinguishable) regardless of whether any individual's data is included or excluded from the dataset.\n",
        "However, a smaller value usually means more noise must be added to the data, which can degrade the utility or accuracy of the algorithm's output.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1wUbCGtdL_UV"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "N = 2048\n",
        "C = 1.0\n",
        "E = 20\n",
        "q = batch_size / N\n",
        "T = E / q\n",
        "delta = 1e-5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VhKzopgY_mbt",
        "outputId": "f8fa8da5-bd15-4423-ea6d-c109597d1c43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /content/drive/MyDrive/ML_Systems/HW6/data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:01<00:00, 103468704.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/drive/MyDrive/ML_Systems/HW6/data/cifar-10-python.tar.gz to /content/drive/MyDrive/ML_Systems/HW6/data\n"
          ]
        }
      ],
      "source": [
        "# Define the mean values and standard deviation values for normalization\n",
        "mean_values = (0.5, 0.5, 0.5)  # Mean values for red, green, and blue channels\n",
        "std_values = (\n",
        "    0.5,\n",
        "    0.5,\n",
        "    0.5,\n",
        ")  # Standard deviation values for red, green, and blue channels\n",
        "\n",
        "# Define the transformation pipeline\n",
        "transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.ToTensor(),  # Convert images to tensors\n",
        "        transforms.Normalize(mean_values, std_values),  # Normalize tensor values\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Load the CIFAR10 training dataset and apply the defined transformations\n",
        "trainset = torchvision.datasets.CIFAR10(\n",
        "    root=data_dir, train=True, download=True, transform=transform\n",
        ")\n",
        "\n",
        "trainsubset = torch.utils.data.Subset(trainset, torch.arange(N))\n",
        "\n",
        "# Create a DataLoader to efficiently load and process training data in batches\n",
        "trainloader = torch.utils.data.DataLoader(\n",
        "    trainsubset, batch_size=batch_size, shuffle=False, num_workers=2\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LN2J7UqXCo8j"
      },
      "source": [
        "## Non-Private Training with SGD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oBu02M4lCo8j",
        "outputId": "50a5f01e-7573-4eff-c431-c6e3f30e57bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 loss: 2.3020\n",
            "Epoch 2 loss: 2.3006\n",
            "Epoch 3 loss: 2.2974\n",
            "Epoch 4 loss: 2.2823\n",
            "Epoch 5 loss: 2.2018\n",
            "Epoch 6 loss: 2.0946\n",
            "Epoch 7 loss: 1.9965\n",
            "Epoch 8 loss: 1.9134\n",
            "Epoch 9 loss: 1.8428\n",
            "Epoch 10 loss: 1.7821\n",
            "Epoch 11 loss: 1.7264\n",
            "Epoch 12 loss: 1.6725\n",
            "Epoch 13 loss: 1.6219\n",
            "Epoch 14 loss: 1.5748\n",
            "Epoch 15 loss: 1.5296\n",
            "Epoch 16 loss: 1.4867\n",
            "Epoch 17 loss: 1.4442\n",
            "Epoch 18 loss: 1.4023\n",
            "Epoch 19 loss: 1.3477\n",
            "Epoch 20 loss: 1.2954\n",
            "Finished Training\n",
            "Accuracy of the network on the train images: 52.001953125%\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def SGD(model, dataloader, lr):\n",
        "    # Define the loss criterion and optimizer\n",
        "    criterion = nn.CrossEntropyLoss()  # Cross-entropy loss for classification\n",
        "    optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "    # Loop over the dataset for multiple epochs\n",
        "    for epoch in range(E):\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for batch in dataloader:\n",
        "            inputs, labels = batch\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            output = model(inputs)\n",
        "            loss = criterion(output, labels)\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            running_loss += loss\n",
        "\n",
        "        print(f\"Epoch {epoch+1} loss: {running_loss/len(dataloader):.4f}\")\n",
        "\n",
        "    print(\"Finished Training\")  # Training loop is complete\n",
        "\n",
        "# Create model and start training\n",
        "net = Net().to(device)\n",
        "SGD(net, trainloader, lr=0.05)\n",
        "\n",
        "score = calculate_accuracy(net, trainloader)\n",
        "print('Accuracy of the network on the train images: {}%'.format(score))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZZrJ9ZpgTrt"
      },
      "source": [
        "## Q1: Privacy-Aware Training with DP-SGD\n",
        "TODO: Change the naive SGD function to make it become differentially private. Please refer to the original [paper](https://arxiv.org/pdf/1607.00133.pdf) for DP-SGD alogrithm.\n",
        "\n",
        "Note that we have removed the pytorch optimizer. Instead, we'll be implementing the optimzer functionality ourselves.\n",
        "\n",
        "We set $\\sigma = 0.05$ and $lr = 0.05$. Note that this training loop has not converged to the optimal weights due to insufficient training epochs, but for simplicity, we stop training after 20 epochs. In practice, to get the optimal accuracy for DP-SGD, we need to run significantly more epochs than naive SGD."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpdkuhRN03sb",
        "outputId": "0a5d39e9-33b3-4960-c761-e229253042c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 loss: 2.3026\n",
            "Epoch 2 loss: 2.3026\n",
            "Epoch 3 loss: 2.3026\n",
            "Epoch 4 loss: 2.3026\n",
            "Epoch 5 loss: 2.3026\n",
            "Epoch 6 loss: 2.3026\n",
            "Epoch 7 loss: 2.3026\n",
            "Epoch 8 loss: 2.3026\n",
            "Epoch 9 loss: 2.3026\n",
            "Epoch 10 loss: 2.3026\n",
            "Epoch 11 loss: 2.3026\n",
            "Epoch 12 loss: 2.3026\n",
            "Epoch 13 loss: 2.3026\n",
            "Epoch 14 loss: 2.3026\n",
            "Epoch 15 loss: 2.3026\n",
            "Epoch 16 loss: 2.3026\n",
            "Epoch 17 loss: 2.3026\n",
            "Epoch 18 loss: 2.3026\n",
            "Epoch 19 loss: 2.3026\n",
            "Epoch 20 loss: 2.3026\n",
            "Finished Training\n",
            "Accuracy of the network on the train images: 8.544921875%\n"
          ]
        }
      ],
      "source": [
        "from torch.nn.utils import clip_grad_norm_\n",
        "\n",
        "def DPSGD(model, dataloader, sigma, lr):\n",
        "    # Define the loss criterion and optimizer\n",
        "    criterion = nn.CrossEntropyLoss()  # Cross-entropy loss for classification\n",
        "\n",
        "    # Loop over the dataset for multiple epochs\n",
        "    for epoch in range(E):\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for batch in dataloader:\n",
        "            inputs, labels = batch\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            for param in model.parameters():\n",
        "                param.accumulated_grads = torch.zeros_like(param)\n",
        "\n",
        "            # Iterate over each input sample and its corresponding label sample\n",
        "            per_batch_loss = 0.0\n",
        "            for input_sample, label_sample in zip(inputs, labels):\n",
        "                input_sample = input_sample.unsqueeze(0)\n",
        "                label_sample = label_sample.unsqueeze(0)\n",
        "\n",
        "                # TODO: Compute gradients per sample\n",
        "                model.zero_grad()\n",
        "                output = model(input_sample)\n",
        "                loss = criterion(output, label_sample)\n",
        "                loss.backward()\n",
        "\n",
        "                # TODO: Accumulate per_sample_loss to per_batch_loss for debugging purpose\n",
        "                per_batch_loss = per_batch_loss + loss.item()\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    # TODO: Clip gradients and add noise, then accumulate gradients\n",
        "                    for param in model.parameters():\n",
        "                      if param.grad is not None:\n",
        "                          clip_grad_norm_(param, max_norm=sigma)\n",
        "                          whiteN = torch.normal(mean=0.0, std=sigma, size=param.grad.size()).to(device)\n",
        "                          param.accumulated_grads += param.grad + whiteN\n",
        "\n",
        "                # TODO: Clear gradients\n",
        "                for param in model.parameters():\n",
        "                  param.grad.zero_()\n",
        "\n",
        "            # TODO: Average per_batch_loss and accumulate it to running_loss for debug purpose\n",
        "            running_loss += per_batch_loss / len(inputs)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                # TODO: Averge accumulated gradients and update parameters\n",
        "                # Please use param.copy_() to set new param\n",
        "                for param in model.parameters():\n",
        "                  updated_param = param.accumulated_grads / len(dataloader)\n",
        "                  param.copy_(updated_param)  # Update parameters using accumulated gradients\n",
        "                  param.accumulated_grads.zero_()  # Reset accumulated gradients\n",
        "\n",
        "        print(f\"Epoch {epoch+1} loss: {running_loss/len(dataloader):.4f}\")\n",
        "\n",
        "    print(\"Finished Training\")  # Training loop is complete\n",
        "\n",
        "# Create model and start training\n",
        "net = Net().to(device)\n",
        "DPSGD(net, trainloader, sigma=0.05, lr=0.05)\n",
        "\n",
        "score = calculate_accuracy(net, trainloader)\n",
        "print('Accuracy of the network on the train images: {}%'.format(score))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3pMMDA_lCo8j"
      },
      "source": [
        "## Q2: Privacy and utility trade-off\n",
        "\n",
        "TODO: Plot how $\\epsilon$ changes as $\\sigma$ is increasing from 0.01 to 1. For the rest of the DP-SGD hyperparameters, use the default values defined above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "SQ9GObu4Co8k",
        "outputId": "2b8e0057-e2ed-48f0-8abd-5014d9f7f9f3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "sigma_values = np.linspace(0.01, 1, 100)\n",
        "epsilon_values = []\n",
        "\n",
        "# TODO: calculate epsilon values for each sigma value based on the formula\n",
        "for sig in sigma_values:\n",
        "  epsilon = q*np.sqrt(T*np.log(1/delta))/sig\n",
        "  epsilon_values.append(epsilon)\n",
        "\n",
        "# Plot sigma vs epsilon\n",
        "plt.plot(sigma_values, epsilon_values)\n",
        "plt.xlabel(\"Sigma\")\n",
        "plt.ylabel(\"Epsilon\")\n",
        "plt.title(\"Sigma vs Epsilon\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2dcImlDSrgA"
      },
      "source": [
        "TODO: Run DP-SGD again with $\\sigma=0.1$ and compare accuracy with the previous experiment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JuCnSlO_S9KJ",
        "outputId": "c16d2d60-e7a0-4ee5-97e1-118e9e042820"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 loss: 2.3026\n",
            "Epoch 2 loss: 2.3026\n",
            "Epoch 3 loss: 2.3026\n",
            "Epoch 4 loss: 2.3026\n",
            "Epoch 5 loss: 2.3026\n",
            "Epoch 6 loss: 2.3026\n",
            "Epoch 7 loss: 2.3026\n",
            "Epoch 8 loss: 2.3026\n",
            "Epoch 9 loss: 2.3026\n",
            "Epoch 10 loss: 2.3026\n",
            "Epoch 11 loss: 2.3026\n",
            "Epoch 12 loss: 2.3026\n",
            "Epoch 13 loss: 2.3026\n",
            "Epoch 14 loss: 2.3026\n",
            "Epoch 15 loss: 2.3026\n",
            "Epoch 16 loss: 2.3026\n",
            "Epoch 17 loss: 2.3026\n",
            "Epoch 18 loss: 2.3026\n",
            "Epoch 19 loss: 2.3026\n",
            "Epoch 20 loss: 2.3026\n",
            "Finished Training\n",
            "Accuracy of the network on the train images: 10.05859375%\n"
          ]
        }
      ],
      "source": [
        "# Create model and start training\n",
        "net = Net().to(device)\n",
        "DPSGD(net, trainloader, sigma=0.1, lr=0.05)\n",
        "\n",
        "score = calculate_accuracy(net, trainloader)\n",
        "print('Accuracy of the network on the train images: {}%'.format(score))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBn3Y939kE2P"
      },
      "source": [
        "TODO:\n",
        "How would privacy guarantee and model accuracy change when we increase the value of $\\sigma$?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The amount of noise injected into the gradients grows as σ, which stands for the standard deviation of the noise added to gradients in privacy-preserving techniques such as Differential Privacy, increases. In fact, by making it more difficult for attackers to extract specific information from the training data, this increased noise improves privacy guarantees.\n",
        "\n",
        "However, the accuracy of the model is sacrificed for this increased privacy protection. The noise introduced to the gradients is more noticeable as σ rises. This may impede the model's learning process and impair its capacity to recognize significant patterns and correlations in the data.\n",
        "Consequently, while stronger privacy measures are achieved with larger σ values, there's a trade-off where the model's utility, represented by its accuracy and performance, might be compromised due to the increased noise.\n"
      ],
      "metadata": {
        "id": "RTgr3t8XHG2L"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qe833eBCo8k"
      },
      "source": [
        "## Q3: System cost\n",
        "\n",
        "TODO: Why is DP-SGD computation much slower than SGD?\n",
        "\n",
        "TODO: For the naive SGD, if there are $P$ trainable parameters, we know that we need to store $P$ gradients during each batch iteration. How many gradients need to store for DP-SGD during each batch iteration?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1\n",
        "To achieve differential privacy, noise is introduced to the gradients in DP-SGD. The process of introducing noise to gradients entails creating random values from a given Gaussian distribution. In comparison to standard SGD, where no such noise is added, this extra computation for noise production and addition greatly increases the computational strain. DP-SGD necessitates computing gradients for each sample separately, in contrast to SGD, which computes gradients for the whole batch of data.\n",
        "\n",
        "#2\n",
        "Total Gradients = P + {batch_size}"
      ],
      "metadata": {
        "id": "AC4X7OlXHVSt"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}